{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using Distributions: Normal\n",
    "using Random\n",
    "import POMDPs: initialstate_distribution, actions, gen, discount, isterminal\n",
    "Random.seed!(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "invalid redefinition of constant SP_POMDP_state",
     "output_type": "error",
     "traceback": [
      "invalid redefinition of constant SP_POMDP_state",
      "",
      "Stacktrace:",
      " [1] top-level scope at /home/himanshu/.julia/packages/IJulia/yLI42/src/kernel.jl:52"
     ]
    }
   ],
   "source": [
    "struct human_goal_location\n",
    "    x:: Int64\n",
    "    y:: Int64\n",
    "end\n",
    "\n",
    "struct pedestrian_state\n",
    "    x:: Int64\n",
    "    y:: Int64\n",
    "    goal:: human_goal_location\n",
    "end\n",
    "\n",
    "struct cart_state\n",
    "    x:: Int64\n",
    "    y:: Int64\n",
    "    theta:: Int64\n",
    "    v:: Int64\n",
    "end    \n",
    "\n",
    "struct observations\n",
    "    observed_human_positions:: Array{human_goal_location}\n",
    "end\n",
    "\n",
    "struct SP_POMDP_state\n",
    "    cart:: cart_state\n",
    "    pedestrians:: Array{pedestrian_state}\n",
    "    pedestrian_goals:: Array{human_goal_location}\n",
    "    path_covered_index:: Int64\n",
    "end\n",
    "\n",
    "struct human_goal_probability\n",
    "    distribution::Array{Float64}\n",
    "end\n",
    "\n",
    "function isgoalstate(s)\n",
    "    cart_x = s.cart.x\n",
    "    cart_y = s.cart.y\n",
    "    cart_goal = m.cart_goal_position\n",
    "    if(cart_goal.x == cart_x && cart_goal.y == cart_y)\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human_goal_location(4, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 =  human_goal_location(4,5)\n",
    "ps1 = pedestrian_state(1,1,g1)\n",
    "ps2 = pedestrian_state(2,2,g1)\n",
    "cs = cart_state(1,2,3,4)\n",
    "pd = SP_POMDP_state(cs,[],[],1)\n",
    "push!(pd.pedestrians,ps1)\n",
    "push!(pd.pedestrians,ps2)\n",
    "pd.pedestrians[2].goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "invalid redefinition of constant Speed_Planner_POMDP",
     "output_type": "error",
     "traceback": [
      "invalid redefinition of constant Speed_Planner_POMDP",
      "",
      "Stacktrace:",
      " [1] top-level scope at /home/himanshu/.julia/packages/IJulia/yLI42/src/kernel.jl:52"
     ]
    }
   ],
   "source": [
    "mutable struct Speed_Planner_POMDP <: POMDPs.POMDP{SP_POMDP_state,Int,observations}\n",
    "    discount_factor::Float64\n",
    "    step_size::Int\n",
    "    collision_threshold::Float64\n",
    "    goal_reward::Int64\n",
    "    max_cart_speed::Int64\n",
    "    cart_goal_position::human_goal_location\n",
    "    starting_cart_state::cart_state\n",
    "    starting_human_states::Array{pedestrian_state}\n",
    "    fixed_goal_locations::Array{human_goal_location}\n",
    "    human_goals_prob_distribution::Array{human_goal_probability}\n",
    "    astar_path::Array{Tuple{Int64,Int64},1}\n",
    "    start_path_index::Int64\n",
    "end\n",
    "Speed_Planner_POMDP() = Speed_Planner_POMDP(0.9,1,2,100,5,)\n",
    "discount(p::Speed_Planner_POMDP) = p.discount_factor\n",
    "isterminal(::Speed_Planner_POMDP, s::SP_POMDP_state) = isgoalstate(s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutable struct LightDark1D <: POMDPs.POMDP{Float64,Int,Int}\n",
    "#     discount_factor::Float64\n",
    "#     correct_r::Float64\n",
    "#     incorrect_r::Float64\n",
    "#     #step_size::Int\n",
    "#     movement_cost::Float64\n",
    "# end\n",
    "# LightDark1D() = LightDark1D(0.9, 10, -10, 1, 0)\n",
    "# discount(p::LightDark1D) = p.discount_factor\n",
    "# isterminal(::LightDark1D, s::Float64) = isnan(s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function POMDPs.gen(m::Speed_Planner_POMDP, s, a, rng)\n",
    "    \n",
    "    # transition model\n",
    "    \n",
    "    function calculate_theta(current_state, previous_state)\n",
    "        theta = 0\n",
    "        x_diff = current_state[1] - previous_state[1]\n",
    "        y_diff = current_state[2] - previous_state[2]\n",
    "        if x_diff != 0\n",
    "            if x_diff < 0\n",
    "                theta = 90\n",
    "            else\n",
    "                theta = 270\n",
    "            end\n",
    "        end\n",
    "        if y_diff != 0\n",
    "            if y_diff < 0\n",
    "                theta = 0\n",
    "            else\n",
    "                theta = 180\n",
    "            end\n",
    "        end\n",
    "        return theta\n",
    "    end\n",
    "    \n",
    "    function update_human_state(human, human_goals, rng)\n",
    "        goal = human.goal\n",
    "        \n",
    "        human_fixed_goals = copy(human_goals)\n",
    "        deleteat!(human_fixed_goals, findall(x -> x==goal, human_fixed_goals)[1])\n",
    "        \n",
    "        rand_num = rand(rng)\n",
    "        \n",
    "        function move_human_towards_goal(human, goal)\n",
    "            temp_human_x = human.x\n",
    "            temp_human_y = human.y\n",
    "            if temp_human_x < goal.x\n",
    "                temp_human_x = temp_human_x + 1\n",
    "            elseif temp_human_x > goal.x\n",
    "                temp_human_x = temp_human_x - 1\n",
    "            end\n",
    "\n",
    "            if temp_human_y < goal.y\n",
    "                temp_human_y = temp_human_y + 1\n",
    "            elseif temp_human_y > goal.y\n",
    "                temp_human_y = temp_human_y - 1\n",
    "            end\n",
    "            return pedestrian_state(temp_human_x, temp_human_y, goal)\n",
    "        end\n",
    "        \n",
    "        if rand_num <= 0.7\n",
    "            # move human towards goal\n",
    "            new_human = move_human_towards_goal(human, goal)\n",
    "        elseif rand_num > 0.7 && rand_num <= 0.8\n",
    "            new_human = move_human_towards_goal(human, human_fixed_goals[1])\n",
    "        elseif rand_num > 0.8 && rand_num <= 0.9\n",
    "            new_human = move_human_towards_goal(human, human_fixed_goals[2])\n",
    "        elseif rand_num > 0.9\n",
    "            new_human = move_human_towards_goal(human, human_fixed_goals[3])\n",
    "        end\n",
    "        return new_human\n",
    "    end\n",
    "\n",
    "    new_pedestrians = []\n",
    "    \n",
    "    # action 0\n",
    "    if a == 0\n",
    "        # kart state +2 steps based on path\n",
    "        # x = new state in path's X\n",
    "        # y = new state in path's Y\n",
    "        # theta = new states - one previous state {if change in x or change in y}\n",
    "        # v = v\n",
    "        new_v = s.cart.v + a\n",
    "        new_position = s.path[s.path_covered_index + new_v]\n",
    "        new_theta = calculate_theta(new_position, s.path[s.path_covered_index + new_v - 1])\n",
    "        cart_new_state = cart_state(new_position[1], new_position[2], new_theta, new_v)\n",
    "        \n",
    "        # pedestrians state +1 step in their path for all pedestrians\n",
    "        # change x\n",
    "        # change y\n",
    "        for human in s.pedestrians\n",
    "            new_human = update_human_state(human, s.pedestrian_goals, rng)\n",
    "            push!(new_pedestrians, new_human)\n",
    "        end\n",
    "        # path {need to change now/later based on A* from kart's current position to goal}\n",
    "        new_path_index = s.path_covered_index + new_v\n",
    "    \n",
    "    # action 1\n",
    "    elseif a == 1\n",
    "        # kart state +3 steps based on path\n",
    "        # x = new state in path's X\n",
    "        # y = new state in path's Y\n",
    "        # theta = new states - one previous state {if change in x or change in y}\n",
    "        # v = v +1\n",
    "        new_v = s.cart.v + a % 5\n",
    "        new_position = s.path[s.path_covered_index + new_v]\n",
    "        new_theta = calculate_theta(new_position, s.path[s.path_covered_index + new_v - 1])\n",
    "        cart_new_state = cart_state(new_position[1], new_position[2], new_theta, new_v)\n",
    "            \n",
    "        # pedestrians state +1 step in their path for all pedestrians\n",
    "        # change x\n",
    "        # change y\n",
    "        for human in s.pedestrians\n",
    "            new_human = update_human_state(human, s.pedestrian_goals, rng)\n",
    "            push!(new_pedestrians, new_human)\n",
    "        end\n",
    "        \n",
    "        # path {need to change now/later based on A* from kart's current position to goal}\n",
    "        new_path_index = s.path_covered_index + new_v\n",
    "        \n",
    "    # action -1\n",
    "    elseif a == -1\n",
    "        # kart state +1 steps based on path\n",
    "        # x = new state in path's X\n",
    "        # y = new state in path's Y\n",
    "        # theta = new states - one previous state {if change in x or change in y}\n",
    "        # v = v -1\n",
    "        new_v = s.cart.v + a\n",
    "        if new_v < 0\n",
    "            new_v = 0\n",
    "        end\n",
    "        new_position = s.path[s.path_covered_index + new_v]\n",
    "        new_theta = calculate_theta(new_position, s.path[s.path_covered_index + new_v - 1])\n",
    "        cart_new_state = cart_state(new_position[1], new_position[2], new_theta, new_v)\n",
    "        \n",
    "        # pedestrians state +1 step in their path for all pedestrians\n",
    "        # change x\n",
    "        # change y\n",
    "        for human in s.pedestrians\n",
    "            new_human = update_human_state(human, s.pedestrian_goals, rng)\n",
    "            push!(new_pedestrians, new_human)\n",
    "        end\n",
    "        \n",
    "        # path {need to change now/later based on A* from kart's current position to goal}\n",
    "        new_path_index = s.path_covered_index + new_v\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # update the state object\n",
    "    sp = SP_POMDP_state(cart_new_state, new_pedestrians, s.pedestrian_goals, s.path, new_path_index)\n",
    "\n",
    "    # observation model\n",
    "    o = new_pedestrians\n",
    "    #This is wrong^\n",
    "    \n",
    "    \n",
    "    # reward model\n",
    "    \n",
    "    # collision reward\n",
    "    function collision_reward(sp, coll_threshold)\n",
    "        total_reward = 0\n",
    "        cart_pose_x = sp.cart.x\n",
    "        cart_pose_y = sp.cart.y\n",
    "        for human in sp.pedestrians\n",
    "            dist = ((human.x - cart_pose_x)^2 + (human.y - cart_pose_y)^2)^0.5\n",
    "            if dist < coll_threshold\n",
    "                total_reward = total_reward - 10\n",
    "            end\n",
    "        end\n",
    "        return total_reward\n",
    "    end\n",
    "    \n",
    "    # goal reward\n",
    "    function goal_reward(sp, s, goal_state_reward)\n",
    "        total_reward = -1\n",
    "        cart_new_pose_x = sp.cart.x\n",
    "        cart_new_pose_y = sp.cart.y\n",
    "        \n",
    "        cart_goal = sp.path[length(sp.path)]\n",
    "        new_dist = ((cart_goal[1] - cart_new_pose_x)^2 + (cart_goal[1] - cart_new_pose_y)^2)^0.5\n",
    "        \n",
    "        cart_old_pose_x = sp.cart.x\n",
    "        cart_old_pose_y = sp.cart.y\n",
    "        old_dist = ((cart_goal[1] - cart_old_pose_x)^2 + (cart_goal[1] - cart_old_pose_y)^2)^0.5\n",
    "        \n",
    "        if new_dist < old_dist && new_dist != 0\n",
    "            total_reward = goal_state_reward/new_dist\n",
    "        elseif new_dist == 0\n",
    "            total_reward = goal_state_reward\n",
    "        end\n",
    "        return total_reward\n",
    "    end\n",
    "    \n",
    "    # speed reward\n",
    "    function speed_reward(sp, max_speed)\n",
    "        return (sp.cart.v - max_speeed)/max_speed\n",
    "    end\n",
    "    \n",
    "    r = collision_reward(sp, m.collision_threshold) + goal_reward(sp, s, m.goal_reward) + speed_reward(sp, m.max_cart_speed)\n",
    "    \n",
    "    # create and return a NamedTuple\n",
    "    return (sp=sp, o=o, r=r)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actions (generic function with 2 methods)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Action Space for the POMDP\n",
    "actions(::Speed_Planner_POMDP) = [-1, 0, 1] # Decelerate Maintain Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialstate_distribution (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialstate_distribution(m::Speed_Planner_POMDP)\n",
    "    initial_cart_state = m.starting_cart_state\n",
    "    all_human_goal_locations = m.fixed_human_goal_locations\n",
    "    initial_human_states = m.starting_human_states\n",
    "    initial_path_start_index = m.start_path_index\n",
    "    initial_human_goal_probability = m.human_goals_prob_distribution\n",
    "    num_goals = length(all_human_goal_locations)\n",
    "    \n",
    "    all_256_possible_states = []\n",
    "    all_256_probability_values = []\n",
    "    \n",
    "    for goal_human1_index in (1:num_goals)\n",
    "        for goal_human2_index in (1:num_goals)\n",
    "            for goal_human3_index in (1:num_goals)\n",
    "                for goal_human4_index in (1:num_goals)\n",
    "                    sampled_human1_sate = pedestrian_state(initial_human_states[1].x,initial_human_states[1].y,all_human_goal_locations[goal_human1_index])\n",
    "                    sampled_human2_sate = pedestrian_state(initial_human_states[2].x,initial_human_states[2].y,all_human_goal_locations[goal_human2_index])\n",
    "                    sampled_human3_sate = pedestrian_state(initial_human_states[3].x,initial_human_states[3].y,all_human_goal_locations[goal_human3_index])\n",
    "                    sampled_human4_sate = pedestrian_state(initial_human_states[4].x,initial_human_states[4].y,all_human_goal_locations[goal_human4_index])\n",
    "                    sampled_humans = [sampled_human1_state, sampled_human2_sate, sampled_human3_sate, sampled_human4_sate]                    \n",
    "                    generated_state = SP_POMDP_state(initial_cart_state,sampled_humans,all_human_goal_locations,initial_path_start_index)\n",
    "                    push!(all_256_possible_states,generated_state)\n",
    "                    \n",
    "                    human1_prob = initial_human_goal_probability[1].distribution[goal_human1_index]\n",
    "                    human2_prob = initial_human_goal_probability[2].distribution[goal_human2_index]\n",
    "                    human3_prob = initial_human_goal_probability[3].distribution[goal_human3_index]\n",
    "                    human4_prob = initial_human_goal_probability[4].distribution[goal_human4_index]\n",
    "                    probability_for_generated_state =  human1_prob*human2_prob*human3_prob*human4_prob\n",
    "                    push!(all_256_probability_values,probability_for_generated_state)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "                    \n",
    "    return SparseCat(all_256_possible_states, all_256_probability_values)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @requirements_info GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?initialstate_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?isterminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialstate_distribution(pomdp::LightDark1D) = Normal(2.0, 3.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Tuple{Int64,Int64},1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Array{Tuple{Int64,Int64},1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Tuple{Int64,Int64},1}:\n",
       " (1, 2)\n",
       " (2, 3)\n",
       " (3, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [(1,2),(2,3),(3,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Tuple{Int64,Int64},1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: m not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: m not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[58]:1"
     ]
    }
   ],
   "source": [
    "actions(m::Speed_Planner_POMDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1\n",
      "i = 2\n",
      "i = 3\n"
     ]
    }
   ],
   "source": [
    "x = 3\n",
    "for i in (1:x)\n",
    "    @show(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{pedestrian_state,1}:\n",
       " pedestrian_state(1, 1, human_goal_location(1, 1))\n",
       " pedestrian_state(1, 2, human_goal_location(1, 1))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg1 = human_goal_location(1,1)\n",
    "p1 = pedestrian_state(1,1,hg1)\n",
    "p2 = pedestrian_state(1,2,hg1)\n",
    "lk = [p1,p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{pedestrian_state,1}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 1\n",
      "b = 2\n",
      "x = 3\n",
      "a = 1\n",
      "b = 2\n",
      "c = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= 1\n",
    "b = 2\n",
    "function lala(x,y)\n",
    "    x = x+2\n",
    "    @show(x)\n",
    "    return x+y\n",
    "end\n",
    "@show(a)\n",
    "@show(b)\n",
    "c = lala(a,b)\n",
    "@show(a)\n",
    "@show(b)\n",
    "@show(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
